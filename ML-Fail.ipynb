{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/diamonds.csv\", index_col = 0)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ideal', 'Premium', 'Good', 'Very Good', 'Fair'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cut\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"cut\"].astype(\"category\").cat.codes\n",
    "\n",
    "# ^ Good for classification, but not so much for features\n",
    "\n",
    "cut_class_dict = {\"Fair\": 1, \"Good\": 2, \"Very Good\": 3, \"Premium\": 4, \"Ideal\": 5}\n",
    "clarity_dict = {\"I3\": 1, \"I2\": 2, \"I1\": 3, \"SI2\": 4, \"SI1\": 5, \"VS2\": 6, \"VS1\": 7, \"VVS2\": 8, \"VVS1\": 9, \"IF\": 10, \"FL\": 11}\n",
    "color_dict = {\"J\": 1,\"I\": 2,\"H\": 3,\"G\": 4,\"F\": 5,\"E\": 6,\"D\": 7}\n",
    "\n",
    "\n",
    "df[\"cut\"] = df[\"cut\"].map(cut_class_dict)\n",
    "df[\"clarity\"] = df[\"clarity\"].map(clarity_dict)\n",
    "df[\"color\"] = df[\"color\"].map(color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "df = sklearn.utils.shuffle(df) # always shuffle your data to avoid any biases that may emerge b/c of some order.\n",
    "\n",
    "X = df.drop(\"price\", axis=1).values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "test_size = 200\n",
    "\n",
    "X_train = X[:-test_size]\n",
    "y_train = y[:-test_size]\n",
    "\n",
    "X_test = X[-test_size:]\n",
    "y_test = y[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2421.036988184998 1746\n",
      "2421.036988184998 2720\n",
      "2421.036988184998 866\n",
      "2421.036988184998 1909\n",
      "2421.036988184998 1060\n",
      "2421.036988184998 1786\n",
      "2421.036988184998 3260\n",
      "2421.036988184998 4153\n",
      "2421.036988184998 1787\n",
      "2421.036988184998 571\n"
     ]
    }
   ],
   "source": [
    "for X,y in list(zip(X_test, y_test))[:10]:\n",
    "    print(clf.predict([X])[0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alec\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4230680129359535\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVR()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alec\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1165.0146792222042\n",
      "248396.13994143903 1746\n",
      "116264.76224177517 2720\n",
      "56188.953592758626 866\n",
      "16772.091514615342 1909\n",
      "58664.250320522115 1060\n",
      "-19680.471159650013 1786\n",
      "-171117.78508750908 3260\n",
      "-10107.577121416107 4153\n",
      "22272.605433832854 1787\n",
      "-152215.4405183904 571\n"
     ]
    }
   ],
   "source": [
    "clf = SGDRegressor(max_iter=10000)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "for X,y in list(zip(X_test, y_test))[:10]:\n",
    "    print(clf.predict([X])[0], y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-937.701222838298\n",
      "Model: 248396.13994143903, Actual: 873\n",
      "Model: 116264.76224177517, Actual: 2691\n",
      "Model: 56188.953592758626, Actual: 1210\n",
      "Model: 16772.091514615342, Actual: 710\n",
      "Model: 58664.250320522115, Actual: 4121\n",
      "Model: -19680.471159650013, Actual: 1343\n",
      "Model: -171117.78508750908, Actual: 13853\n",
      "Model: -10107.577121416107, Actual: 958\n",
      "Model: 22272.605433832854, Actual: 8688\n",
      "Model: -152215.4405183904, Actual: 5439\n",
      "Model: 68978.2839895282, Actual: 5484\n",
      "Model: -87734.3187185619, Actual: 2959\n",
      "Model: -177862.40719932131, Actual: 579\n",
      "Model: 98993.61897949688, Actual: 1654\n",
      "Model: -2538.436501370743, Actual: 2376\n",
      "Model: 52222.6512282677, Actual: 3418\n",
      "Model: 5435.4121597427875, Actual: 4523\n",
      "Model: 69493.8907203544, Actual: 610\n",
      "Model: 145155.1337373834, Actual: 798\n",
      "Model: -118341.40593166836, Actual: 1607\n",
      "Model: -197679.51613794267, Actual: 3572\n",
      "Model: -74220.15671867318, Actual: 1558\n",
      "Model: 168772.71800226718, Actual: 5335\n",
      "Model: -128300.8733159285, Actual: 2289\n",
      "Model: 71463.41318834946, Actual: 867\n",
      "Model: -24048.269977228716, Actual: 1799\n",
      "Model: 39010.980857007205, Actual: 7582\n",
      "Model: -151779.39494521543, Actual: 4323\n",
      "Model: -29848.966653088108, Actual: 754\n",
      "Model: 60173.12386892922, Actual: 904\n",
      "Model: 47130.16179281287, Actual: 11035\n",
      "Model: -48104.51315809786, Actual: 5944\n",
      "Model: 118264.31013048254, Actual: 5255\n",
      "Model: -250208.30891301297, Actual: 1013\n",
      "Model: 136765.4832776338, Actual: 1399\n",
      "Model: -15951.051034612581, Actual: 765\n",
      "Model: -44814.814285274595, Actual: 1367\n",
      "Model: 59992.6691962257, Actual: 756\n",
      "Model: 8893.794508354738, Actual: 4823\n",
      "Model: 235356.85951244272, Actual: 1222\n",
      "Model: -193378.2584412042, Actual: 1046\n",
      "Model: -93227.78760041296, Actual: 7244\n",
      "Model: 80058.26719912514, Actual: 4672\n",
      "Model: -107952.00614777952, Actual: 4857\n",
      "Model: 470.32180802337825, Actual: 612\n",
      "Model: -77050.05314715765, Actual: 8886\n",
      "Model: -71566.83005428687, Actual: 503\n",
      "Model: 28624.350735977292, Actual: 787\n",
      "Model: 107149.96667198278, Actual: 929\n",
      "Model: 13958.432152923197, Actual: 2329\n",
      "Model: -116766.94413254783, Actual: 943\n",
      "Model: 129825.26065041684, Actual: 573\n",
      "Model: 101656.76206986234, Actual: 1080\n",
      "Model: 90061.84930405393, Actual: 855\n",
      "Model: 230474.31580860727, Actual: 3166\n",
      "Model: 71283.1540580932, Actual: 3359\n",
      "Model: -134129.42954833433, Actual: 919\n",
      "Model: -97114.30503144674, Actual: 17760\n",
      "Model: 179329.94664342143, Actual: 4167\n",
      "Model: 3066.6661110129207, Actual: 6366\n",
      "Model: -87743.51383008808, Actual: 9483\n",
      "Model: 57297.46060937829, Actual: 18128\n",
      "Model: 25745.74340513535, Actual: 7661\n",
      "Model: 73563.73167094402, Actual: 6532\n",
      "Model: 63590.16867491789, Actual: 7500\n",
      "Model: -86306.61009613425, Actual: 649\n",
      "Model: 81640.26643067412, Actual: 603\n",
      "Model: 142749.7104579229, Actual: 4798\n",
      "Model: 34385.80764213391, Actual: 2772\n",
      "Model: -130069.44943236187, Actual: 13968\n",
      "Model: -584359.9863532819, Actual: 1235\n",
      "Model: 125837.78767355718, Actual: 1815\n",
      "Model: -276138.73205687664, Actual: 645\n",
      "Model: 40664.41325470619, Actual: 8736\n",
      "Model: -170010.58803640865, Actual: 2978\n",
      "Model: -59098.845453653485, Actual: 5593\n",
      "Model: 69213.9496706985, Actual: 10744\n",
      "Model: -89473.13513778336, Actual: 1080\n",
      "Model: 1410.7893226202577, Actual: 839\n",
      "Model: 23841.349976688623, Actual: 772\n",
      "Model: 48679.156811913475, Actual: 4036\n",
      "Model: 12449.807815065607, Actual: 645\n",
      "Model: 96790.62158810906, Actual: 432\n",
      "Model: 132378.07073900476, Actual: 1155\n",
      "Model: -13031.647809738293, Actual: 3197\n",
      "Model: -191170.86873804778, Actual: 4692\n",
      "Model: 181628.47798434086, Actual: 886\n",
      "Model: -289070.2714460511, Actual: 5519\n",
      "Model: -70028.22928304784, Actual: 2250\n",
      "Model: -304691.6174410302, Actual: 1295\n",
      "Model: 131836.8636013195, Actual: 666\n",
      "Model: 55599.97131657973, Actual: 6805\n",
      "Model: 74531.07286982611, Actual: 3662\n",
      "Model: 47401.281060637906, Actual: 789\n",
      "Model: -195032.21685725637, Actual: 1294\n",
      "Model: -58829.4108107388, Actual: 2760\n",
      "Model: -77235.69333510101, Actual: 16363\n",
      "Model: 25105.131091516465, Actual: 901\n",
      "Model: -175213.5826413948, Actual: 6156\n",
      "Model: 100226.83970240317, Actual: 1013\n",
      "Model: 133491.87242725678, Actual: 5062\n",
      "Model: 18899.520938931033, Actual: 666\n",
      "Model: 29527.31838322617, Actual: 13574\n",
      "Model: -70324.03099774756, Actual: 5791\n",
      "Model: -137491.4571858812, Actual: 7813\n",
      "Model: 66948.71891778149, Actual: 3046\n",
      "Model: 147836.31689722277, Actual: 668\n",
      "Model: 44791.13584145345, Actual: 1053\n",
      "Model: -139327.9653663505, Actual: 10232\n",
      "Model: 173222.09011521563, Actual: 2443\n",
      "Model: 99188.03402610682, Actual: 434\n",
      "Model: -177471.52476741932, Actual: 743\n",
      "Model: -128891.27398852259, Actual: 4558\n",
      "Model: 278207.5396489538, Actual: 11336\n",
      "Model: 71880.7798324842, Actual: 1367\n",
      "Model: 147556.6208939962, Actual: 3801\n",
      "Model: -102498.61398348771, Actual: 14362\n",
      "Model: 18699.006001839414, Actual: 15841\n",
      "Model: 149612.20070998557, Actual: 2475\n",
      "Model: 69495.25230819546, Actual: 485\n",
      "Model: 108708.21084007807, Actual: 547\n",
      "Model: 122925.32255815156, Actual: 586\n",
      "Model: -33523.057561103255, Actual: 619\n",
      "Model: -83382.92377743125, Actual: 4004\n",
      "Model: -68502.40943803452, Actual: 2548\n",
      "Model: -141890.59516644105, Actual: 605\n",
      "Model: -8601.449725406244, Actual: 14482\n",
      "Model: -131502.2825088948, Actual: 10477\n",
      "Model: -127138.7991582267, Actual: 1020\n",
      "Model: -54797.2054012008, Actual: 486\n",
      "Model: -96825.29054209031, Actual: 596\n",
      "Model: -80362.2892396804, Actual: 1095\n",
      "Model: 57413.93622681871, Actual: 5305\n",
      "Model: 93683.7661055047, Actual: 860\n",
      "Model: -182717.50737877563, Actual: 4978\n",
      "Model: 102752.35562097467, Actual: 694\n",
      "Model: -171207.40014429577, Actual: 1253\n",
      "Model: 29685.08175139129, Actual: 4445\n",
      "Model: -60579.86541473307, Actual: 1902\n",
      "Model: 150990.55869820341, Actual: 1172\n",
      "Model: -147151.7792458404, Actual: 1706\n",
      "Model: 133607.35791988857, Actual: 2339\n",
      "Model: 210665.86357782222, Actual: 2276\n",
      "Model: 56600.61207404733, Actual: 910\n",
      "Model: -42624.5062454734, Actual: 5430\n",
      "Model: 114307.5005701594, Actual: 6702\n",
      "Model: 66453.21718615107, Actual: 3326\n",
      "Model: 288956.1664588917, Actual: 4586\n",
      "Model: -73230.63429758698, Actual: 4295\n",
      "Model: -80858.82403704897, Actual: 12554\n",
      "Model: -38048.79508425109, Actual: 1401\n",
      "Model: 17231.29446456395, Actual: 10823\n",
      "Model: 8707.06684558466, Actual: 2058\n",
      "Model: -45775.00548123196, Actual: 945\n",
      "Model: -103210.57508302666, Actual: 14727\n",
      "Model: 224568.07778179273, Actual: 655\n",
      "Model: -120383.62606594898, Actual: 14867\n",
      "Model: -124876.21302247792, Actual: 733\n",
      "Model: 58958.68524779938, Actual: 4276\n",
      "Model: 2752.766020061448, Actual: 568\n",
      "Model: -92275.01008782722, Actual: 16704\n",
      "Model: 15665.029073443264, Actual: 1845\n",
      "Model: 46359.56691968627, Actual: 3823\n",
      "Model: -9457.105756161734, Actual: 451\n",
      "Model: -326689.0972464774, Actual: 6325\n",
      "Model: 162873.06025643274, Actual: 2753\n",
      "Model: -188320.4328677673, Actual: 4381\n",
      "Model: 234786.40842287987, Actual: 2875\n",
      "Model: -236357.230409896, Actual: 850\n",
      "Model: 16265.06310926564, Actual: 2050\n",
      "Model: -63633.10200174712, Actual: 805\n",
      "Model: 121855.65674787201, Actual: 3445\n",
      "Model: 157812.38289587758, Actual: 10824\n",
      "Model: 145800.30766581185, Actual: 7582\n",
      "Model: 68396.02128117345, Actual: 1023\n",
      "Model: 64415.79657538049, Actual: 1356\n",
      "Model: 134820.5422568284, Actual: 15134\n",
      "Model: 116475.18450179137, Actual: 2565\n",
      "Model: 50042.18727567978, Actual: 2107\n",
      "Model: 23996.39690415375, Actual: 2048\n",
      "Model: 62130.61741010286, Actual: 2516\n",
      "Model: -88502.86762444675, Actual: 1061\n",
      "Model: -39163.03139256872, Actual: 689\n",
      "Model: 47882.116843936965, Actual: 846\n",
      "Model: 17033.034061221406, Actual: 12099\n",
      "Model: 95787.79181567952, Actual: 2475\n",
      "Model: 30334.17326491885, Actual: 4398\n",
      "Model: 46943.1476463452, Actual: 684\n",
      "Model: 256986.55886744335, Actual: 2535\n",
      "Model: 31465.22501397878, Actual: 988\n",
      "Model: 129038.75699184276, Actual: 1707\n",
      "Model: 123090.67999054492, Actual: 5713\n",
      "Model: -22552.482508217916, Actual: 906\n",
      "Model: 84803.11243963428, Actual: 603\n",
      "Model: 1478.7623308934271, Actual: 470\n",
      "Model: 339102.2523892578, Actual: 586\n",
      "Model: -30653.30408159457, Actual: 11452\n",
      "Model: 55546.76757375151, Actual: 1050\n",
      "Model: -23592.50408791937, Actual: 10317\n",
      "Model: 32562.444115703925, Actual: 6039\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test,Y_test))\n",
    "for X,Y in zip(X_test, Y_test):\n",
    "    print(f\"Model: {clf.predict([X])[0]}, Actual: {Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
